{"paragraphs":[{"text":"To run this script, first ensure that you run the first 3 sections to install scikit-learn, gensim, and download the NLTK stopwords.\nThis script will load the cleaned data from the JusText Clean script, and the tokenized data from the Tokenize script, then rank articles\nby their most frequent words, and output a percentage of them to articles.txt to be used in the other Unit7 Python script.\n\n","user":"anonymous","dateUpdated":"2018-12-06T20:52:35+0000","config":{"colWidth":12,"fontSize":12,"enabled":false,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544129157947_460010467","id":"20181206-204557_1557916673","dateCreated":"2018-12-06T20:45:57+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5637","title":"Unit 7 Setup Script"},{"text":"%python.conda install scikit-learn","user":"anonymous","dateUpdated":"2018-12-04T16:49:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1542128792740_129325108","id":"20181113-170632_2050938184","dateCreated":"2018-11-13T17:06:32+0000","dateStarted":"2018-12-04T16:49:28+0000","dateFinished":"2018-12-04T16:51:37+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3951"},{"text":"%python.conda install gensim","user":"anonymous","dateUpdated":"2018-12-06T20:47:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1543201769179_98585843","id":"20181126-030929_1479992158","dateCreated":"2018-11-26T03:09:29+0000","dateStarted":"2018-12-04T16:49:32+0000","dateFinished":"2018-12-04T16:52:00+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3952"},{"text":"%pyspark\nimport nltk\nnltk.download('stopwords')","user":"anonymous","dateUpdated":"2018-12-04T16:49:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1543297249131_1895894713","id":"20181127-054049_1022477026","dateCreated":"2018-11-27T05:40:49+0000","dateStarted":"2018-12-04T16:49:43+0000","dateFinished":"2018-12-04T16:50:03+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3953"},{"text":"%pyspark\n# You should run JusText Clean on your input JSON before this script\ncleanDF = spark.read.json(\"/share_dir/Attack_Westminster_big_cleaned.json\")\ncleanDF.count()","user":"anonymous","dateUpdated":"2018-12-04T17:00:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"6900\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=0","http://172.17.0.2:4040/jobs/job?id=1"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1542126752216_-1704681703","id":"20181113-163232_1699980224","dateCreated":"2018-11-13T16:32:32+0000","dateStarted":"2018-12-04T17:00:23+0000","dateFinished":"2018-12-04T17:00:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3954"},{"text":"%pyspark\n# This section, and the latter one were used when we were attempting to summarize at a sentence level rather than an article level.\n# We chose not to continue this method after it was found that those summaries generated had little flow, and would duplicate a lot\n# of information.\n\n# import nltk\n# from nltk.tokenize import sent_tokenize, word_tokenize\n\n# sents = list(set(cleanDF.rdd.flatMap(lambda x: sent_tokenize(x.text.encode('ascii', 'ignore'))).filter(lambda x: len(word_tokenize(x)) < 50).collect()))\n# len(sents)","user":"anonymous","dateUpdated":"2018-12-06T20:50:30+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1542126755132_-1233255722","id":"20181113-163235_1503807403","dateCreated":"2018-11-13T16:32:35+0000","dateStarted":"2018-11-26T02:27:49+0000","dateFinished":"2018-11-26T02:28:15+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3955","errorMessage":""},{"text":"%pyspark\n# f = open('/share_dir/sents.txt', 'w')\n# for sent in sents:\n#     f.write(sent.encode('ascii', 'ignore') + '\\n')\n# f.close()","user":"anonymous","dateUpdated":"2018-12-06T20:47:39+0000","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1542126789054_-1200351987","id":"20181113-163309_12935831","dateCreated":"2018-11-13T16:33:09+0000","dateStarted":"2018-11-26T03:07:30+0000","dateFinished":"2018-11-26T03:07:30+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:3956","errorMessage":""},{"text":"%pyspark\ntokensDF = spark.read.json(\"/share_dir/Attack_Westminster_big_tokenized.json\")\ntokensDF.show()","user":"anonymous","dateUpdated":"2018-12-04T17:00:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+\n|         originalUrl|                text|               title|              tokens|        tokens_lower|tokens_with_stopwords|\n+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+\n|https://www.stand...|A rail source mea...|Boss of rail awar...|[rail, source, me...|[rail, source, me...| [A, rail, source,...|\n|http://www.indepe...|But many others h...|Manchester terror...|[many, others, pr...|[many, others, pr...| [But, many, other...|\n|http://www.9news....|Islamic State cla...|Islamic State cla...|[Islamic, State, ...|[islamic, state, ...| [Islamic, State, ...|\n|https://www.thesu...|The incident come...|Donald Trump Jnr ...|[incident, comes,...|[incident, comes,...| [The, incident, c...|\n|https://www.googl...|A teenager plotte...|UK all-female ISI...|[teenager, plotte...|[teenager, plotte...| [A, teenager, plo...|\n|http://mwcnews.ne...|Police identify B...|London police: Ei...|[Police, identify...|[police, identify...| [Police, identify...|\n|https://www.thesu...|Mr Ellwood, who l...|Who was Keith Pal...|[Mr, Ellwood, los...|[mr, ellwood, los...| [Mr, Ellwood, who...|\n|https://www.googl...|But the woman – w...|Twitter photo Mus...|[woman, remained,...|[woman, remained,...| [But, the, woman,...|\n|https://www.thegu...|Floral tributes t...|Ofcom condemns Ch...|[Floral, tributes...|[floral, tributes...| [Floral, tributes...|\n|http://www.huffin...|London Attack Vic...|London Attack Vic...|[London, Attack, ...|[london, attack, ...| [London, Attack, ...|\n|https://www.opend...|Postscript to a l...|Postscript to a l...|[Postscript, lett...|[postscript, lett...| [Postscript, to, ...|\n|https://www.buzzf...|Everyone Arrested...|Everyone Arrested...|[Everyone, Arrest...|[everyone, arrest...| [Everyone, Arrest...|\n|https://www.buzzf...|Khalid Masood, th...|This Is What We K...|[Khalid, Masood, ...|[khalid, masood, ...| [Khalid, Masood, ...|\n|http://www.watch-...|Hans Zimmer Is Th...|Hans Zimmer Is Th...|[Hans, Zimmer, Th...|[hans, zimmer, th...| [Hans, Zimmer, Is...|\n|http://terrorism....|About Trendolizer...|All-female ISIS j...|[Trendolizer, Tre...|[trendolizer, tre...| [About, Trendoliz...|\n|http://www.newbur...|Police name alleg...|Police name alleg...|[Police, name, al...|[police, name, al...| [Police, name, al...|\n|http://www.irisht...|Westminster attac...|Westminster attac...|[Westminster, att...|[westminster, att...| [Westminster, att...|\n|http://www.indepe...|Soldiers reinforc...|Police cuts mean ...|[Soldiers, reinfo...|[soldiers, reinfo...| [Soldiers, reinfo...|\n|http://veaterecos...|Friday, 24 March ...|Veater Ecosan: \"T...|[Friday, 24, Marc...|[friday, 24, marc...| [Friday, 24, Marc...|\n|http://www.thelon...|Labour MP Laura P...|Laura Pidcock lau...|[Labour, MP, Laur...|[labour, mp, laur...| [Labour, MP, Laur...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=2","http://172.17.0.2:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1542218743080_-354757444","id":"20181114-180543_1801806168","dateCreated":"2018-11-14T18:05:43+0000","dateStarted":"2018-12-04T17:00:27+0000","dateFinished":"2018-12-04T17:00:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3957"},{"text":"%pyspark\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef filterDuplicates(data, eps = 0.9, verbose = False):\n    vectorizer = TfidfVectorizer(max_df=0.5,min_df=2,stop_words='english')\n    X = vectorizer.fit_transform(data)\n    pairwise_similarity = X * X.T\n    toRemove = set()\n    for i, pair in enumerate(pairwise_similarity.A):\n        if i not in toRemove:\n            for j, p in enumerate(pair):\n                if i != j and p > eps:\n                    toRemove.add(j)\n    toRemove = list(toRemove)\n    toRemove.sort(reverse=True)\n    for i in toRemove:\n        p = data.pop(i)\n    if verbose:\n        print('Removed:', len(toRemove))","user":"anonymous","dateUpdated":"2018-12-04T17:00:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1543300437955_-1533181702","id":"20181127-063357_906765575","dateCreated":"2018-11-27T06:33:57+0000","dateStarted":"2018-12-04T17:00:43+0000","dateFinished":"2018-12-04T17:00:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3958"},{"text":"%pyspark\ndata = cleanDF.rdd.map(lambda x: x.text).collect()\nvectorizer = TfidfVectorizer(max_df=0.5,min_df=2,stop_words='english')\nX = vectorizer.fit_transform(data)\npairwise_similarity = X * X.T\ntoRemove = set()\nfor i, pair in enumerate(pairwise_similarity.A):\n    if i not in toRemove:\n        for j, p in enumerate(pair):\n            if i != j and p > eps:\n                toRemove.add(j)\n                # print(data[j])","user":"anonymous","dateUpdated":"2018-11-29T15:57:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Fail to execute line 9:             if i != j and p > eps:\nTraceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-6372162755097992102.py\", line 380, in <module>\n    exec(code, _zcUserQueryNameSpace)\n  File \"<stdin>\", line 9, in <module>\nNameError: name 'eps' is not defined\n"}]},"apps":[],"jobName":"paragraph_1543429832190_681583322","id":"20181128-183032_176633699","dateCreated":"2018-11-28T18:30:32+0000","dateStarted":"2018-11-29T15:57:47+0000","dateFinished":"2018-11-29T15:58:00+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:3959"},{"text":"%pyspark\nfrom nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\nfrom collections import defaultdict\nfrom heapq import nlargest\n\narticles = cleanDF.rdd.map(lambda x: x.text).collect()\nfilterDuplicates(articles, verbose=True)\n\nfreq = FreqDist()\nword_freqs = tokensDF.rdd.map(lambda x: FreqDist(x.tokens_lower)).collect()\nfor word_freq in word_freqs:\n    freq.update(word_freq)\nfreq = {i:j for i, j in freq.most_common(50)}\n\nranking = defaultdict(int)\n\nfor i, sent in enumerate(articles):\n    for w in word_tokenize(sent.lower()):\n        if w in freq:\n            ranking[i] += freq[w]","user":"anonymous","dateUpdated":"2018-12-04T17:01:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"('Removed:', 2904)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=4","http://172.17.0.2:4040/jobs/job?id=5"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1542127732634_1434758270","id":"20181113-164852_408822547","dateCreated":"2018-11-13T16:48:52+0000","dateStarted":"2018-12-04T17:01:19+0000","dateFinished":"2018-12-04T17:02:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3961"},{"text":"%pyspark\nprint(freq)","user":"anonymous","dateUpdated":"2018-12-04T17:01:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{u'bridge': 14446, u'family': 5734, u'people': 26519, u'house': 6401, u'scene': 5812, u'birmingham': 5594, u'one': 15705, u'woman': 6271, u'london': 24099, u'british': 6768, u'armed': 5788, u'terrorist': 9906, u'police': 45011, u'would': 10003, u'officers': 9215, u'uk': 5820, u'westminster': 30792, u'attack': 39338, u'statement': 5947, u'terror': 9792, u'terrorism': 7540, u'three': 6477, u'public': 5566, u'day': 5725, u'told': 8180, u'injured': 9113, u'parliament': 18396, u'around': 6364, u'outside': 6627, u'may': 11057, u'palmer': 7482, u'attacker': 10178, u'incident': 9390, u'masood': 13110, u'two': 9371, u'services': 6545, u'keith': 5651, u'killed': 7890, u'man': 10532, u'like': 5674, u'attacks': 5659, u'car': 10154, u'us': 10597, u'officer': 10722, u'2017': 6239, u'time': 6521, u'including': 6287, u'security': 10259, u'first': 6311, u'minister': 7696}\n"}]},"apps":[],"jobName":"paragraph_1543306714254_850337162","id":"20181127-081834_827451598","dateCreated":"2018-11-27T08:18:34+0000","dateStarted":"2018-12-04T17:01:21+0000","dateFinished":"2018-12-04T17:02:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3962"},{"text":"%pyspark\nn = int(len(articles) * 0.25)\nsentsIDX = nlargest(n, ranking, key=ranking.get)\nsummaryArr = [articles[j] for j in sorted(sentsIDX)]\nprint(len(summaryArr))","user":"anonymous","dateUpdated":"2018-12-06T20:52:57+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"999\n"}]},"apps":[],"jobName":"paragraph_1543252505358_168304325","id":"20181126-171505_1090313813","dateCreated":"2018-11-26T17:15:05+0000","dateStarted":"2018-12-06T20:52:58+0000","dateFinished":"2018-12-06T20:52:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3963"},{"text":"%pyspark\nf = open('/share_dir/articles.txt', 'w')\nfor art in summaryArr:\n    f.write(art.encode('ascii', 'ignore') + '\\n')\nf.close()","user":"anonymous","dateUpdated":"2018-12-05T21:34:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1543271453763_746134756","id":"20181126-223053_454831134","dateCreated":"2018-11-26T22:30:53+0000","dateStarted":"2018-12-05T21:34:21+0000","dateFinished":"2018-12-05T21:34:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3964"},{"text":"%pyspark\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport numpy as np\n\ndef kmeans_cluster(samples, n_clusters, verbose=False):\n    vectorizer = TfidfVectorizer(max_df=0.5,min_df=2,stop_words='english')\n    X = vectorizer.fit_transform(samples)\n    km = KMeans(n_clusters = n_clusters, max_iter = 100, n_init = 5, verbose = verbose)\n    km.fit(X)\n    np.unique(km.labels_, return_counts=True)\n\n    text={}\n    for i,cluster in enumerate(km.labels_):\n        oneDocument = summaryArr[i]\n        if cluster not in text.keys():\n            # text[cluster] = oneDocument\n            text[cluster] = [oneDocument]\n        else:\n            # text[cluster] += oneDocument + '\\n'\n            text[cluster].append(oneDocument)\n    if verbose:\n        stopWords = set(stopwords.words('english')+list(punctuation))\n        keywords = {}\n        counts={}\n        for cluster in range(n_clusters):\n            word_sent = word_tokenize(('\\n'.join(text[cluster])).lower())\n            word_sent=[word for word in word_sent if word not in stopWords]\n            freq = FreqDist(word_sent)\n            keywords[cluster] = nlargest(100, freq, key=freq.get)\n            counts[cluster]=freq\n        uniqueKeys={}\n        for cluster in range(n_clusters):   \n            other_clusters=list(set(range(n_clusters))-set([cluster]))\n            keys_other_clusters=set(keywords[other_clusters[0]]).union(set(keywords[other_clusters[1]]))\n            unique=set(keywords[cluster])-keys_other_clusters\n            uniqueKeys[cluster]=nlargest(10, unique, key=counts[cluster].get)\n        print(uniqueKeys)\n    return text","user":"anonymous","dateUpdated":"2018-11-26T18:41:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1542218985876_1765675498","id":"20181114-180945_1972131782","dateCreated":"2018-11-14T18:09:45+0000","dateStarted":"2018-11-26T18:41:23+0000","dateFinished":"2018-11-26T18:41:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3965"},{"text":"%pyspark\nvectorizer = TfidfVectorizer(max_df=0.5,min_df=2,stop_words='english')\nX = vectorizer.fit_transform(summaryArr)\npairwise_similarity = X * X.T\ntoRemove = set()\nfor i, pair in enumerate(pairwise_similarity.A):\n    if i not in toRemove:\n        for j, p in enumerate(pair):\n            if i != j and p > 0.9:\n                toRemove.add(j)\ntoRemove = list(toRemove)\ntoRemove.sort(reverse=True)\nprint(toRemove, len(toRemove))\nfor i in toRemove:\n    summaryArr.pop(i)\nprint(len(summaryArr))","user":"anonymous","dateUpdated":"2018-11-26T18:41:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"([343, 342, 341, 340, 339, 338, 337, 336, 335, 334, 333, 331, 330, 329, 328, 327, 326, 325, 323, 321, 320, 318, 316, 315, 314, 313, 312, 311, 310, 309, 308, 306, 305, 304, 303, 302, 301, 300, 299, 296, 294, 293, 292, 291, 290, 289, 286, 283, 282, 280, 279, 278, 277, 276, 275, 273, 271, 269, 267, 263, 262, 260, 259, 258, 254, 253, 249, 248, 245, 243, 242, 241, 240, 238, 237, 236, 235, 234, 232, 231, 230, 228, 227, 226, 225, 224, 223, 221, 218, 217, 215, 213, 212, 211, 210, 209, 208, 207, 206, 204, 203, 202, 200, 199, 198, 195, 193, 191, 189, 188, 187, 185, 184, 180, 179, 177, 176, 173, 170, 168, 167, 166, 164, 159, 158, 156, 155, 154, 152, 151, 147, 145, 143, 142, 138, 137, 134, 133, 132, 131, 130, 129, 124, 123, 119, 116, 115, 113, 112, 111, 110, 108, 107, 104, 103, 101, 99, 98, 97, 96, 94, 91, 89, 88, 87, 85, 84, 81, 80, 78, 77, 76, 75, 74, 73, 72, 71, 69, 68, 63, 61, 60, 59, 58, 57, 55, 54, 53, 51, 50, 45, 39, 37, 36, 35, 33, 32, 30, 29, 27, 26, 23, 20, 19, 18, 17, 16, 12, 10, 7, 6, 4], 212)\n133\n"}]},"apps":[],"jobName":"paragraph_1543250023030_-1544834746","id":"20181126-163343_1414385284","dateCreated":"2018-11-26T16:33:43+0000","dateStarted":"2018-11-26T18:41:23+0000","dateFinished":"2018-11-26T18:41:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3966"},{"text":"%pyspark\ntext = kmeans_cluster(summaryArr, 5, True)","user":"anonymous","dateUpdated":"2018-11-26T18:41:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Initialization complete\nIteration  0, inertia 201.620\nIteration  1, inertia 109.884\nIteration  2, inertia 109.516\nIteration  3, inertia 109.456\nIteration  4, inertia 109.397\nConverged at iteration 4: center shift 0.000000e+00 within tolerance 8.457906e-09\nInitialization complete\nIteration  0, inertia 194.566\nIteration  1, inertia 108.577\nIteration  2, inertia 107.620\nIteration  3, inertia 107.279\nIteration  4, inertia 107.218\nIteration  5, inertia 107.155\nConverged at iteration 5: center shift 0.000000e+00 within tolerance 8.457906e-09\nInitialization complete\nIteration  0, inertia 198.522\nIteration  1, inertia 109.130\nIteration  2, inertia 108.686\nIteration  3, inertia 108.539\nIteration  4, inertia 108.463\nConverged at iteration 4: center shift 0.000000e+00 within tolerance 8.457906e-09\nInitialization complete\nIteration  0, inertia 206.782\nIteration  1, inertia 110.091\nIteration  2, inertia 109.569\nIteration  3, inertia 109.386\nIteration  4, inertia 109.337\nConverged at iteration 4: center shift 0.000000e+00 within tolerance 8.457906e-09\nInitialization complete\nIteration  0, inertia 209.123\nIteration  1, inertia 109.181\nIteration  2, inertia 108.440\nConverged at iteration 2: center shift 0.000000e+00 within tolerance 8.457906e-09\n{0: [u'15', u'photos', u'deadly', u'hide', u'caption', u'officer', u'cnn', u'--', u'house', u'attacker'], 1: [u'muslim', u'islamic', u'2018', u'islam', u'manchester', u'government', u'like', u'muslims', u'attacks', u'august'], 2: [u'cyclists', u'suspect', u'vehicle', u'fiesta', u'around', u'crash', u'barriers', u'barrier', u'khater', u'area'], 3: [u'palace', u'pa', u'major', u'reuters', u'policeman', u'heard', u'apparent', u'images', u'close', u'dealing'], 4: [u'today', u'around', u'palace', u'woman', u'following', u'theresa', u'says', u'street', u'back', u'news']}\n"}]},"apps":[],"jobName":"paragraph_1543251478178_66003913","id":"20181126-165758_1693037308","dateCreated":"2018-11-26T16:57:58+0000","dateStarted":"2018-11-26T18:41:25+0000","dateFinished":"2018-11-26T18:41:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3967"},{"text":"%pyspark\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom gensim.summarization.summarizer import summarize\ndef summarize_text(text, ratio = 0.05):\n    if len(sent_tokenize(text)) > 1:\n        return ' '.join(summarize(text, ratio=ratio, split=True))\n    return \" \"\ndef summarize_cluster(cluster, wc = 300):\n    cluster_items = cluster.items()\n    cluster_items.sort(key=lambda x: len(x[1]), reverse=True)\n    total_size = sum([len(x[1]) for x in cluster_items])\n    summaries = [summarize_text(x[1]) for x in cluster_items]\n    return ' '.join(summaries)","user":"anonymous","dateUpdated":"2018-11-26T18:41:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1543195583898_1369823758","id":"20181126-012623_21017214","dateCreated":"2018-11-26T01:26:23+0000","dateStarted":"2018-11-26T18:41:34+0000","dateFinished":"2018-11-26T18:41:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3968"},{"text":"%pyspark\n# For some reason multiprocessing or threading gensim's summarize function crashes.\n# Instead, we finished the code in a python script on our local machine.\n\n# from multiprocessing import Pool\n# p = Pool()\n# summaries = p.map(lambda x: summarize_text, text[0])\n# text_items = text.items()\n# text_items.sort(key=lambda x: len(x[1]), reverse=True)\n# print(text_items)\n# summary = \"\"\n# for i, t in text_items:\n#     print(i, 'start')\n#     summaries = sc.parallelize(t).map(summarize_text).collect()\n#     print(i, 'middle')\n#     summary += summarize_text('\\n'.join(summaries)) + '\\n'\n# print(summary)","user":"anonymous","dateUpdated":"2018-12-06T20:45:44+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1543198531102_383409465","id":"20181126-021531_850702768","dateCreated":"2018-11-26T02:15:31+0000","dateStarted":"2018-11-26T18:41:35+0000","dateFinished":"2018-11-26T18:42:13+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3969"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2018-11-26T17:35:56+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1542221615903_2035444661","id":"20181114-185335_703832882","dateCreated":"2018-11-14T18:53:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3970"}],"name":"Unit 7","id":"2DVM6HEP4","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}